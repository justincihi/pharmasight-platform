"""
Research Article Database System
Tracks all articles scanned by the autonomous research engine
Provides public database with article metadata for transparency and IP protection
"""

import json
import csv
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional

class ResearchArticleDatabase:
    """Manages database of research articles scanned by autonomous engine"""
    
    def __init__(self, db_path="data/RESEARCH_ARTICLES_DATABASE.json"):
        self.db_path = db_path
        self.csv_path = db_path.replace('.json', '.csv')
        self.database = self._load_database()
    
    def _load_database(self) -> Dict:
        """Load existing database or create new one"""
        if Path(self.db_path).exists():
            with open(self.db_path, 'r') as f:
                return json.load(f)
        else:
            return {
                "database_name": "PharmaSight‚Ñ¢ Research Article Database",
                "description": "Public database of all research articles scanned by autonomous research engine",
                "created": datetime.now().isoformat(),
                "last_updated": datetime.now().isoformat(),
                "total_articles": 0,
                "articles": []
            }
    
    def add_article(self, 
                   title: str,
                   authors: Optional[List[str]] = None,
                   doi: Optional[str] = None,
                   pmid: Optional[str] = None,
                   journal: Optional[str] = None,
                   year: Optional[int] = None,
                   abstract: Optional[str] = None,
                   url: Optional[str] = None,
                   keywords: Optional[List[str]] = None,
                   relevance_score: Optional[float] = None,
                   scan_date: Optional[str] = None,
                   source_database: Optional[str] = None,
                   research_goal: Optional[str] = None) -> Dict:
        """Add a new article to the database"""
        
        article = {
            "article_id": f"ART-{len(self.database['articles']) + 1:05d}",
            "title": title,
            "authors": authors or [],
            "doi": doi,
            "pmid": pmid,
            "journal": journal,
            "year": year,
            "abstract": abstract[:500] if abstract else None,  # Truncate for storage
            "url": url,
            "keywords": keywords or [],
            "relevance_score": relevance_score,
            "scan_date": scan_date or datetime.now().isoformat(),
            "source_database": source_database,
            "research_goal": research_goal,
            "added_to_database": datetime.now().isoformat()
        }
        
        self.database['articles'].append(article)
        self.database['total_articles'] = len(self.database['articles'])
        self.database['last_updated'] = datetime.now().isoformat()
        
        return article
    
    def add_articles_batch(self, articles: List[Dict]) -> int:
        """Add multiple articles at once"""
        count = 0
        for article_data in articles:
            self.add_article(**article_data)
            count += 1
        return count
    
    def save(self):
        """Save database to JSON and CSV files"""
        # Save JSON
        with open(self.db_path, 'w') as f:
            json.dump(self.database, f, indent=2)
        
        # Save CSV
        if self.database['articles']:
            with open(self.csv_path, 'w', newline='', encoding='utf-8') as f:
                fieldnames = ['article_id', 'title', 'authors', 'doi', 'pmid', 'journal', 
                            'year', 'url', 'keywords', 'relevance_score', 'scan_date', 
                            'source_database', 'research_goal']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                
                for article in self.database['articles']:
                    row = {k: article.get(k) for k in fieldnames}
                    # Convert lists to strings for CSV
                    if isinstance(row['authors'], list):
                        row['authors'] = '; '.join(row['authors'])
                    if isinstance(row['keywords'], list):
                        row['keywords'] = ', '.join(row['keywords'])
                    writer.writerow(row)
        
        return self.db_path, self.csv_path
    
    def search_by_doi(self, doi: str) -> Optional[Dict]:
        """Search for article by DOI"""
        for article in self.database['articles']:
            if article.get('doi') == doi:
                return article
        return None
    
    def search_by_keyword(self, keyword: str) -> List[Dict]:
        """Search for articles by keyword"""
        results = []
        keyword_lower = keyword.lower()
        for article in self.database['articles']:
            if keyword_lower in article.get('title', '').lower():
                results.append(article)
            elif any(keyword_lower in kw.lower() for kw in article.get('keywords', [])):
                results.append(article)
        return results
    
    def get_statistics(self) -> Dict:
        """Get database statistics"""
        articles = self.database['articles']
        
        stats = {
            "total_articles": len(articles),
            "articles_with_doi": sum(1 for a in articles if a.get('doi')),
            "articles_with_pmid": sum(1 for a in articles if a.get('pmid')),
            "unique_journals": len(set(a.get('journal') for a in articles if a.get('journal'))),
            "year_range": (
                min((a.get('year') for a in articles if a.get('year')), default=None),
                max((a.get('year') for a in articles if a.get('year')), default=None)
            ),
            "source_databases": list(set(a.get('source_database') for a in articles if a.get('source_database'))),
            "research_goals": list(set(a.get('research_goal') for a in articles if a.get('research_goal')))
        }
        
        return stats
    
    def generate_public_readme(self, output_path="/home/ubuntu/pharmasight-latest/RESEARCH_ARTICLES_README.md"):
        """Generate public README for the article database"""
        stats = self.get_statistics()
        
        readme = f"""# PharmaSight‚Ñ¢ Research Article Database

## Overview

This database contains all research articles scanned by the PharmaSight‚Ñ¢ autonomous research engine. It serves as a transparent record of the literature review process and supports intellectual property documentation.

## Database Statistics

- **Total Articles:** {stats['total_articles']}
- **Articles with DOI:** {stats['articles_with_doi']}
- **Articles with PMID:** {stats['articles_with_pmid']}
- **Unique Journals:** {stats['unique_journals']}
- **Year Range:** {stats['year_range'][0] or 'N/A'} - {stats['year_range'][1] or 'N/A'}
- **Last Updated:** {self.database['last_updated']}

## Source Databases

{chr(10).join(f'- {db}' for db in stats['source_databases']) if stats['source_databases'] else '- None yet'}

## Research Goals Covered

{chr(10).join(f'- {goal}' for goal in stats['research_goals']) if stats['research_goals'] else '- None yet'}

## File Formats

1. **JSON Database:** `RESEARCH_ARTICLES_DATABASE.json`
   - Complete article metadata including abstracts
   - Machine-readable format for programmatic access
   - Full search and filtering capabilities

2. **CSV Spreadsheet:** `RESEARCH_ARTICLES_DATABASE.csv`
   - Simple spreadsheet format for easy viewing
   - Compatible with Excel, Google Sheets, etc.
   - Includes: Article ID, Title, Authors, DOI, PMID, Journal, Year, URL, Keywords

## Usage

### Viewing the Database

**Option 1: CSV Spreadsheet (Easiest)**
- Open `RESEARCH_ARTICLES_DATABASE.csv` in Excel or Google Sheets
- Sort and filter by any column
- Search for specific articles or keywords

**Option 2: JSON Database (Programmatic)**
```python
import json

with open('RESEARCH_ARTICLES_DATABASE.json', 'r') as f:
    database = json.load(f)

# Access all articles
articles = database['articles']

# Search by DOI
doi_to_find = "10.1038/example"
article = next((a for a in articles if a.get('doi') == doi_to_find), None)
```

## Citation

When referencing this database, please use:

```
PharmaSight‚Ñ¢ Research Article Database. Available at: 
https://github.com/justincihi/pharmasight-platform/blob/analog-discoveries-ip-protected/RESEARCH_ARTICLES_DATABASE.json
Last updated: {self.database['last_updated']}
```

## Article Fields

Each article entry contains:

- **article_id:** Unique identifier (ART-00001, ART-00002, etc.)
- **title:** Full article title
- **authors:** List of authors
- **doi:** Digital Object Identifier
- **pmid:** PubMed ID
- **journal:** Journal name
- **year:** Publication year
- **abstract:** Article abstract (truncated to 500 chars)
- **url:** Direct link to article
- **keywords:** Relevant keywords
- **relevance_score:** Relevance to research goals (0-100)
- **scan_date:** Date article was scanned
- **source_database:** Database source (PubMed, arXiv, etc.)
- **research_goal:** Associated research goal

## Maintenance

This database is automatically updated by the PharmaSight‚Ñ¢ autonomous research engine. Manual additions can be made using the ResearchArticleDatabase API.

## License

This database is maintained for research and intellectual property documentation purposes. Individual articles remain under their respective publishers' copyrights.

---

**Generated:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S UTC')}
"""
        
        with open(output_path, 'w') as f:
            f.write(readme)
        
        return output_path

def initialize_with_sample_articles():
    """Initialize database with sample articles from PharmaSight research"""
    db = ResearchArticleDatabase()
    
    # Sample articles related to PharmaSight research goals
    sample_articles = [
        {
            "title": "Psilocybin for treatment-resistant depression: fMRI-measured brain mechanisms",
            "authors": ["Carhart-Harris RL", "Bolstridge M", "Day CMJ", "Rucker J", "Watts R"],
            "doi": "10.1038/s41598-017-13282-7",
            "journal": "Scientific Reports",
            "year": 2017,
            "keywords": ["psilocybin", "depression", "fMRI", "5-HT2A receptor"],
            "relevance_score": 95.0,
            "source_database": "PubMed",
            "research_goal": "Novel 5-HT2A Partial Agonist Discovery for Treatment-Resistant Depression"
        },
        {
            "title": "Ketamine and other NMDA antagonists: early clinical trials and possible mechanisms in depression",
            "authors": ["Zarate CA Jr", "Singh JB", "Carlson PJ", "Brutsche NE", "Ameli R"],
            "doi": "10.1176/appi.ajp.2006.05081283",
            "pmid": "16816223",
            "journal": "American Journal of Psychiatry",
            "year": 2006,
            "keywords": ["ketamine", "NMDA", "depression", "rapid antidepressant"],
            "relevance_score": 98.0,
            "source_database": "PubMed",
            "research_goal": "NMDA Receptor Subtype-Selective Antagonist for Rapid Antidepressant Action"
        },
        {
            "title": "MDMA-assisted therapy for severe PTSD: a randomized, double-blind, placebo-controlled phase 3 study",
            "authors": ["Mitchell JM", "Bogenschutz M", "Lilienstein A", "Harrison C", "Kleiman S"],
            "doi": "10.1038/s41591-021-01336-3",
            "pmid": "33972795",
            "journal": "Nature Medicine",
            "year": 2021,
            "keywords": ["MDMA", "PTSD", "psychotherapy", "serotonin", "oxytocin"],
            "relevance_score": 92.0,
            "source_database": "PubMed",
            "research_goal": "Entactogen Development for PTSD Treatment"
        },
        {
            "title": "Kava lactones and the kava-kava controversy",
            "authors": ["Teschke R", "Sarris J", "Schweitzer I"],
            "doi": "10.1016/j.phymed.2011.07.005",
            "journal": "Phytomedicine",
            "year": 2011,
            "keywords": ["kava", "kavain", "anxiolytic", "GABA", "safety"],
            "relevance_score": 88.0,
            "source_database": "PubMed",
            "research_goal": "Novel Anxiolytic Development from Natural Products"
        },
        {
            "title": "Muscimol as a potent and selective orthosteric agonist of GABAA receptors",
            "authors": ["Johnston GA"],
            "doi": "10.1111/j.1476-5381.2012.02144.x",
            "journal": "British Journal of Pharmacology",
            "year": 2013,
            "keywords": ["muscimol", "GABA-A", "agonist", "anxiolytic", "sleep"],
            "relevance_score": 90.0,
            "source_database": "PubMed",
            "research_goal": "GABA-A Receptor Subtype-Selective Agonist Development"
        },
        {
            "title": "Mescaline: A Global History of the First Psychedelic",
            "authors": ["Jay M"],
            "doi": "10.1080/02791072.2019.1606472",
            "journal": "Journal of Psychoactive Drugs",
            "year": 2019,
            "keywords": ["mescaline", "psychedelic", "5-HT2A", "history", "peyote"],
            "relevance_score": 85.0,
            "source_database": "PubMed",
            "research_goal": "Psychedelic Analog Development for Depression and Addiction"
        }
    ]
    
    count = db.add_articles_batch(sample_articles)
    db.save()
    readme_path = db.generate_public_readme()
    
    return db, count, readme_path

if __name__ == "__main__":
    print("Initializing Research Article Database...")
    db, count, readme_path = initialize_with_sample_articles()
    
    print(f"\n‚úÖ Successfully initialized database with {count} sample articles")
    print(f"\nüìÅ Files created:")
    print(f"   - {db.db_path}")
    print(f"   - {db.csv_path}")
    print(f"   - {readme_path}")
    
    stats = db.get_statistics()
    print(f"\nüìä Database Statistics:")
    print(f"   Total Articles: {stats['total_articles']}")
    print(f"   Articles with DOI: {stats['articles_with_doi']}")
    print(f"   Unique Journals: {stats['unique_journals']}")
    print(f"   Year Range: {stats['year_range'][0]}-{stats['year_range'][1]}")
    print(f"   Source Databases: {', '.join(stats['source_databases'])}")

